{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "persistent-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/shy-frustrum-pointnets/train /home/ubuntu/shy-frustrum-pointnets\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from train.shy_provider import *\n",
    "from models.shy_frustrum_pointnet import *\n",
    "ROOT_DIR = os.path.abspath('')\n",
    "OUT_DIR = os.path.join(ROOT_DIR, 'outputs')\n",
    "TEST_LOG = os.path.join(OUT_DIR, 'test')\n",
    "TRAIN_LOG = os.path.join(OUT_DIR, 'train')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mobile-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_CNT = 0\n",
    "BATCH_SIZE = 32\n",
    "NUM_POINT = 2048\n",
    "MAX_EPOCH = 201\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "# GPU_INDEX = FLAGS.gpu\n",
    "# MOMENTUM = FLAGS.momentum\n",
    "OPTIMIZER = 'adam'\n",
    "NUM_CHANNEL =  4 # point feature channel\n",
    "NUM_CLASSES = 2 # segmentation has two classes\n",
    "\n",
    "MODEL_PATH = os.path.join(OUT_DIR, \"model_120.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "plastic-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preparation\n",
    "\n",
    "train_dataset = FrustumDataset(npoints=NUM_POINT, split='train',\n",
    "        rotate_to_center=True, random_flip=True, random_shift=True, one_hot = True)\n",
    "test_dataset = FrustumDataset(npoints=NUM_POINT, split='val',\n",
    "    rotate_to_center=True, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recovered-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=int(4))\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=int(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romance-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded '/home/ubuntu/shy-frustrum-pointnets/outputs/model_120.pth'.\n"
     ]
    }
   ],
   "source": [
    "# Creating and loading Frustrum_pointnet\n",
    "in_dims = 4\n",
    "net = FrustrumPointNent_v1(in_dims)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    \n",
    "net.load_state_dict(torch.load(MODEL_PATH))\n",
    "print(\"Loaded '{}'.\".format(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "level-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(data, net, writer=None):\n",
    "    batch_data, batch_label, batch_center, batch_heading_class, batch_heading_residual, \\\n",
    "    batch_size_class, batch_size_residual, batch_rot_angle, batch_one_hot_vec = data\n",
    "    \n",
    "    batch_data = batch_data.float().cuda()\n",
    "    batch_one_hot_vec = batch_one_hot_vec.float().cuda()\n",
    "    \n",
    "    batch_label = batch_label.long()\n",
    "    batch_center = batch_center.float()\n",
    "    batch_heading_class = batch_heading_class.long()\n",
    "    batch_heading_residual = batch_heading_residual.float()\n",
    "    batch_size_class = batch_size_class.long()\n",
    "    batch_size_residual = batch_size_residual.float()\n",
    "    batch_rot_angle = batch_rot_angle.float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        end_points = net.eval()(batch_data, batch_one_hot_vec)\n",
    "\n",
    "        loss = get_loss(batch_label, batch_center, batch_heading_class, \\\n",
    "                        batch_heading_residual, batch_size_class, batch_size_residual, end_points, None, None)\n",
    "    \n",
    "    \n",
    "        iou2ds, iou3ds = compute_box3d_iou(end_points['center'].detach().numpy(), end_points['heading_scores'].detach().numpy(), end_points['heading_residuals'].detach().numpy(), \\\n",
    "                          end_points['size_scores'].detach().numpy(), end_points['size_residuals'].detach().numpy(), \\\n",
    "                          batch_center.numpy(), batch_heading_class.numpy(), batch_heading_residual.numpy(), batch_size_class.numpy(), batch_size_residual.numpy())\n",
    "        correct = (torch.argmax(end_points['mask_logits'], 2) == batch_label )\n",
    "        accuracy = torch.sum(correct.float()) / float(BATCH_SIZE*NUM_POINT)\n",
    "\n",
    "    return loss.detach().numpy(), accuracy.numpy(), np.mean(iou2ds), np.mean(iou3ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch_test(dataset, dataloader, train, epoch = None,\n",
    "        writer=None):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_iou2ds = 0.0\n",
    "    total_iou3ds = 0.0\n",
    "    n_data = 0\n",
    "    epoch_str = '' if epoch is None else '[Epoch {}/{}]'.format(\n",
    "            str(epoch).zfill(len(str(MAX_EPOCH))), MAX_EPOCH)\n",
    "    \n",
    "    # Create a progress bar.\n",
    "    pbar = tqdm(total=n_data, leave=False)\n",
    "    \n",
    "    mode = 'Train' if train else 'Test'\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Run one step.\n",
    "        loss, seg_accuracy, mean_iou2ds, mean_iou3ds = run_test(data, net, writer) \n",
    "        \n",
    "        \n",
    "\n",
    "        batch_size = list(data[0].size())[0]\n",
    "        total_loss += (loss * batch_size)\n",
    "        total_acc += (seg_accuracy * batch_size)\n",
    "        total_iou2ds += (mean_iou2ds * batch_size)\n",
    "        total_iou3ds += (mean_iou3ds * batch_size)\n",
    "    \n",
    "        pbar.set_description('{} {} Loss: {:f}, SegAcc : {:.2f}%'.format(\n",
    "            epoch_str, mode, loss, seg_accuracy))\n",
    "        pbar.update(batch_size)\n",
    "        n_data += batch_size\n",
    "\n",
    "    \n",
    "    pbar.close()\n",
    "    mean_loss = total_loss / float(n_data)\n",
    "    mean_acc = total_acc / float(n_data)\n",
    "    mean_2d = total_iou2ds/float(n_data)\n",
    "    mean_3d = total_iou3ds/float(n_data)\n",
    "    \n",
    "    if writer!= None:\n",
    "        step = epoch * 300 + i\n",
    "        writer.add_scalar('Loss/Test', loss, step)\n",
    "        writer.add_scalar('SegmentationAccuracy/Test', seg_accuracy, step)\n",
    "        writer.add_scalar('iou2d/Test', mean_iou2ds, step)\n",
    "        writer.add_scalar('ioud3d/Test', mean_iou3ds, step)\n",
    "\n",
    "    return mean_loss, mean_acc, mean_2d, mean_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "demographic-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.481410, Test SegmentationAcc: 0.904816, Test iou2d, iou3d: 0.33%, 0.28%, \n",
      "Train Loss: 4.982156, Train SegmentationAcc: 0.93%, Train iou2d, iou3d: 0.36%, 0.31%, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "# testing on test and train datasets\n",
    "mean_test_loss, mean_test_acc, mean_test_2d, mean_test_3d = run_epoch_test(\n",
    "    test_dataset, test_dataloader, False, epoch, None)\n",
    "\n",
    "mean_train_loss, mean_train_acc, mean_train_2d, mean_train_3d = run_epoch_test(\n",
    "    train_dataset, train_dataloader, False, epoch, None)\n",
    "\n",
    "log =\"\"\n",
    "log += 'Test Loss: {:f}, '.format(mean_test_loss)\n",
    "log += 'Test SegmentationAcc: {:f}, '.format(mean_test_acc)\n",
    "log += 'Test iou2d, iou3d: {:.2f}%, {:.2f}%, '.format(mean_test_2d, mean_test_3d)\n",
    "print(log)\n",
    "log =\"\"\n",
    "log += 'Train Loss: {:f}, '.format(mean_train_loss)\n",
    "log += 'Train SegmentationAcc: {:.2f}%, '.format(mean_train_acc)\n",
    "log += 'Train iou2d, iou3d: {:.2f}%, {:.2f}%, '.format(mean_train_2d, mean_train_3d)\n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
